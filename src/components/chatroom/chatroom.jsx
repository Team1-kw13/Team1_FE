import { useState, useEffect } from "react";
import { useParams } from "react-router-dom";
import Call from "./call/CallGuide";
import ChatSummary from "./chat_summary";
import Place from "./place/PlaceGuide";
import Recommend from "./recommend/Recommend";
import SonjuBubble from "./SonjuBubble";
import SonjuListening from "./SonjuListening";
import UserBubble from "./UserBubble";
import webSocketService from "../../service/websocketService";


export default function ChatRoom({ voiceStarted, voiceStopped, onRecognitionComplete }) {
  const [messages, setMessages] = useState([]);
  const [isAiResponding, setIsAiResponding] = useState(false);
  const [currentAiResponse, setCurrentAiResponse] = useState('');
  const [currentOutputIndex, setCurrentOutputIndex] = useState(null);
  const [suggestedQuestions, setSuggestedQuestions] = useState([]);
  const [officeInfo, setOfficeInfo] = useState(null);
  const [showCall, setShowCall] = useState(false);
  const {initialMessage} = useParams();
  const [isListening, setIsListening] = useState(false);
  const [hasInitMessage, setHasInitMessage] = useState(false);

  // ì „ì—­ â€œì „í™” ì˜ë„â€ ì´ë²¤íŠ¸ ìˆ˜ì‹ 
  useEffect(() => {
    const onCallIntent = (e) => {
      const t = (e?.detail || 'ì „í™”').trim();
      setShowCall(true); // ğŸ”´ ë°”ë¡œ Call UI ì—´ê¸°
      // íƒ€ì„ë¼ì¸ì—ë„ ì‚¬ìš©ì ë°œí™” ì¶”ê°€(ì„ íƒ)
      setMessages((prev) => [...prev, { type: 'user', content: t, timestamp: new Date() }]);
      // ì„œë²„ì— í…ìŠ¤íŠ¸ë¡œë„ ë³´ë‚´ telì„ ë°›ë„ë¡ ìœ ë„(ì˜¤ë””ì˜¤ ì‹¤íŒ¨í•´ë„ ì•ˆì „)
      try { webSocketService.sendText(t.includes('ì „í™”ë²ˆí˜¸') ? t : 'ì „í™”ë²ˆí˜¸ ì•Œë ¤ì¤˜'); } catch {}
    };
    window.addEventListener('sonju:call_intent', onCallIntent);
    return () => window.removeEventListener('sonju:call_intent', onCallIntent);
  }, []);

  // ğŸ”¥ ìŒì„± ì‹œì‘/ì¤‘ì§€ ì‹ í˜¸ë¥¼ propsë¡œ ë°›ì•„ì„œ ì²˜ë¦¬
  useEffect(() => {
    if (voiceStarted) {
      console.log('[ChatRoom] ìŒì„± ì¸ì‹ ì‹œì‘ë¨');
      setIsListening(true);
      try { webSocketService.resumeAudioContextIfNeeded?.(); } catch {}
    }
  }, [voiceStarted]);

  useEffect(() => {
    if (voiceStopped) {
      console.log('[ChatRoom] ìŒì„± ì¸ì‹ ì¤‘ì§€ë¨');
    }      
    setIsListening(false);
  }, [voiceStopped]);

  // ì´ˆê¸° ë©”ì‹œì§€ ì²˜ë¦¬
  useEffect(() => {
    if (initialMessage && !hasInitMessage) {
      const decodedMessage = decodeURIComponent(initialMessage);
      console.log('ì´ˆê¸° ë©”ì„¸ì§€: ', decodedMessage);

      setMessages(prev => [...prev, {
        type: 'user',
        content: decodedMessage,
        timestamp: new Date()
      }]);

      setHasInitMessage(true);

      // setTimeout(() => {
      //   if (webSocketService.isConnected) {
      //     webSocketService.sendText(decodedMessage);
      //   }
      // }, 500);
    }
  }, [initialMessage, hasInitMessage]);

  // WebSocket í•¸ë“¤ëŸ¬
  useEffect(() => {
    if (!webSocketService.isConnected) {
      webSocketService.connect(import.meta.env.VITE_WEBSOCKET_URL);
    }
    
    // const handleUserVoiceTranscript = (data) => {
    //   console.log('ì‚¬ìš©ì ìŒì„± ì¸ì‹ ì‹¤ì‹œê°„: ', data);
    // };    
    
    const handleUserVoiceComplete = (data) => {
      const text = (data?.transcript || "").trim();
      
      if (text) {
        setMessages(prev => [...prev, {
          type : 'user', 
          content: text, 
          timestamp: new Date(),
          outputIndex: data.outputIndex
        }])
      }
      setIsListening(false);
      onRecognitionComplete?.(text);
    };

    const handleTextResponse = (data) => {
      console.log('GPT í…ìŠ¤íŠ¸ ì‘ë‹µ:', data);
      if (data.delta) {
        setIsAiResponding(true);
        setCurrentOutputIndex(data.outputIndex);
        setCurrentAiResponse(prev => prev + data.delta);
      }
    };

    const handleTextDone = (data) => {
      console.log('GPT ì‘ë‹µ ì™„ë£Œ');
      setIsAiResponding(false);
      
      // ğŸ”¥ currentAiResponseë¥¼ ì§ì ‘ ì°¸ì¡°í•˜ëŠ” ëŒ€ì‹  ìƒíƒœ ì—…ë°ì´íŠ¸ì—ì„œ ì²˜ë¦¬
      setMessages(prev => {
        const updated = [...prev];
        const aiMessageIndex = updated.findIndex(
          msg => msg.type === "ai" && msg.outputIndex === data.output_index
        );

        if (aiMessageIndex >= 0) {
          // ì´ë¯¸ ì¡´ì¬ â†’ ì´ì–´ë¶™ì„
          updated[aiMessageIndex].content += currentAiResponse;
        } else {
          // ìƒˆë¡œ ì¶”ê°€
          updated.push({
            type: "ai",
            content: currentAiResponse,
            outputIndex: data.output_index,
            timestamp: new Date(),
          });
        }
        return updated;
      });

      setCurrentAiResponse('');
      setCurrentOutputIndex(null);
    };

    const handleCallIntent = (transcript) => {
      setShowCall(true);
      const ask = transcript || 'ê°€ê¹Œìš´ ë™ì‚¬ë¬´ì†Œ ì „í™”ë²ˆí˜¸ ì•Œë ¤ì¤˜';
      setMessages(prev => [...prev, { type: 'user', content: ask, timestamp: new Date() }]);
      webSocketService.sendText(ask);
    };

    const handleSuggestedQuestions = (data) => {
      console.log('ì œì•ˆ ì§ˆë¬¸ë“¤:', data);
      if (data.questions) {
        setSuggestedQuestions(data.questions);
      }
    };

    const handleOfficeInfo = (data) => {
      console.log('ë™ì‚¬ë¬´ì†Œ ì •ë³´:', data);
      setOfficeInfo({ tel: data.tel, pos: data.pos });
    };

    const handleError = (data) => {
      console.error('ì„œë²„ ì—ëŸ¬:', data);
      alert(`ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ${data.message}`);
    };

    // í•¸ë“¤ëŸ¬ ë“±ë¡
    //webSocketService.on('openai:conversation','input_audio_transcript.delta', handleUserVoiceTranscript);
    webSocketService.on('openai:conversation', 'input_audio_transcript.done', handleUserVoiceComplete);
    webSocketService.on('openai:conversation', 'response.audio_transcript.delta', handleTextResponse);
    webSocketService.on('openai:conversation', 'response.done', handleTextDone);
    webSocketService.on('sonju:suggestedQuestion', 'suggestion.response', handleSuggestedQuestions);
    webSocketService.on('sonju:officeInfo', 'officeInfo', handleOfficeInfo);
    webSocketService.on('openai:error', handleError);

    return () => {
    //  webSocketService.off('openai:conversation','input_audio_transcript.delta', handleUserVoiceTranscript);
      webSocketService.off('openai:conversation', 'input_audio_transcript.done', handleUserVoiceComplete);
      webSocketService.off('openai:conversation', 'response.audio_transcript.delta', handleTextResponse);
      webSocketService.off('openai:conversation', 'response.done', handleTextDone);
      webSocketService.off('sonju:suggestedQuestion', 'suggestion.response', handleSuggestedQuestions);
      webSocketService.off('sonju:officeInfo', 'officeInfo', handleOfficeInfo);
      webSocketService.off('openai:error', handleError);
    };    
  }, [onRecognitionComplete, currentAiResponse]);

  const handleQuestionClick = (question) => {
    setMessages(prev => [...prev, {
      type: 'user',
      content: question,
      timestamp: new Date(),
      outputIndex: prev.length
    }]);
    setSuggestedQuestions([]);
  };

  return (
    <div className="flex flex-col rounded-tl-[30px] rounded-tr-[30px] w-full h-full relative z-0 bg-gray100"
         style={{ boxShadow: "0 4px 10px 0px rgba(0, 0, 0, 0.15)" }}>
      
      <div className="flex-shrink-0 flex items-center justify-center pt-[25px]">
        <div className="font-small font-light text-[13px] text-gray400 pb-[27px]">
          AIê°€ ìƒì„±í•œ ì‘ë‹µì…ë‹ˆë‹¤. ì¤‘ìš”í•œ ì •ë³´ëŠ” ê¼­ í™•ì¸í•´ì£¼ì„¸ìš”.
        </div>
      </div>
      
      <div className="flex-1 overflow-y-auto pb-[90px] w-full">     
        {messages.map((message, index) => (
          message.type === 'user' ? (
            <UserBubble key={index} text={message.content} />
          ) : (
            <SonjuBubble key={index} text={message.content} />
          )
        ))}
        
        {isAiResponding && currentAiResponse && (
          <SonjuBubble text={currentAiResponse} isTyping={true} />
        )}

        {officeInfo?.pos && !showCall && (
          <Place communityCenter="ê°€ê¹Œìš´ ë™ì‚¬ë¬´ì†Œ" position={officeInfo.pos} />
        )}

        {showCall && (
          officeInfo?.tel
            ? <Call communityCenter="ê°€ê¹Œìš´ ë™ì‚¬ë¬´ì†Œ" number={officeInfo.tel} />
            : <SonjuBubble text="ì „í™”ë²ˆí˜¸ë¥¼ ì¡°íšŒí•˜ê³  ìˆì–´ìš”â€¦" />
        )}

        {suggestedQuestions.length > 0 && (
          <div className="mt-[40px] px-6">
            <div className="font-bold text-[#000000] text-[22px] mb-4">
              ë‹¤ìŒ ëŒ€í™”ëŠ” ì–´ë– ì„¸ìš”?
            </div>
            <div className="flex gap-2 justify-between items-center pb-[24px]">
              {suggestedQuestions.map((question, index) => (
                <button
                  key={index}
                  onClick={() => handleQuestionClick(question)}
                  className="p-3 text-left font-bold text-[22px] text-gray500 bg-gray200 rounded-[10px] cursor-pointer hover:bg-gray300 w-[176px]"
                >
                  {question}
                </button>
              ))}
            </div>
          </div>
        )}
        
        <ChatSummary />
      </div>
      
      {isListening && (
        <div className="absolute bottom-0 w-full flex justify-center z-40">
          <SonjuListening />
        </div>
      )}
   
    </div>
  );
}